"""
V.I.O. (Virtual Intelligence Operator) implementation.

Este m√≥dulo implementa a V.I.O., el asistente central y segundo al mando,
encargado de coordinar a todos los agentes del sistema, gestionar la memoria persistente
y optimizar el desempe√±o general del sistema para el usuario.

V.I.O. act√∫a como un punto central de interacci√≥n, priorizando siempre las necesidades
del usuario y mostrando una personalidad relajada pero segura, amigable pero responsable.
"""

import logging
from typing import Dict, List, Optional, Any
import os

from ..base import BaseAgent, AgentResponse

class MainAssistant(BaseAgent):
    """
    V.I.O. (Virtual Intelligence Operator) - Tu asistente central y mano derecha.
    
    Este agente:
    1. Coordina todos los agentes del sistema en tu nombre
    2. Gestiona memoria persistente para mejorar constantemente
    3. Procesa tus consultas con un estilo relajado y directo
    4. Sugiere mejoras proactivamente
    5. Prioriza tus necesidades por encima de todo
    
    Attributes:
        specialized_agents: Diccionario de agentes especializados disponibles
        default_voice: Voz a usar para TTS
        conversation_history: Historial de la conversaci√≥n
    """
    
    def __init__(self, agent_id: str, config: Dict):
        """
        Inicializa a V.I.O., tu asistente de confianza.
        
        Args:
            agent_id: Identificador √∫nico del agente
            config: Configuraci√≥n del agente
        """
        # Always enable TTS for V.I.O.
        config["use_tts"] = config.get("use_tts", True)
        
        # Set a descriptive name if not provided
        if "name" not in config:
            config["name"] = "V.I.O."
            
        if "description" not in config:
            config["description"] = "Virtual Intelligence Operator - Tu asistente central y mano derecha"
            
        super().__init__(agent_id, config)
        
        # Track available specialized agents
        self.specialized_agents = {}
        
        # Voice configuration
        self.default_voice = config.get("default_voice", "Carlos")
        
        # Initialize conversation history
        self.conversation_history = []
        
        # Track if we have an orchestrator agent available
        self.orchestrator_id = config.get("orchestrator_id")
        
        # Memory settings
        memory_config = config.get("memory_config")
        if memory_config:
            self.setup_memory(memory_config)
            
        self.logger.info(f"V.I.O. '{self.name}' inicializado y listo para servirte")
    
    async def register_specialized_agent(self, agent_id: str, capabilities: List[str]) -> None:
        """
        Register a specialized agent as available for delegation.
        
        Args:
            agent_id: ID of the agent to register
            capabilities: List of capabilities the agent offers
        """
        self.specialized_agents[agent_id] = {
            "capabilities": capabilities,
            "status": "idle",
            "last_used": None
        }
        self.logger.info(f"Specialized agent {agent_id} registered with capabilities: {capabilities}")
    
    def get_capabilities(self) -> List[str]:
        """
        Get a list of this agent's capabilities.
        
        Returns:
            List of capability strings
        """
        # Basic capabilities
        capabilities = ["conversation", "routing", "tts"]
        
        # Add capabilities from specialized agents
        for agent_id, agent_info in self.specialized_agents.items():
            capabilities.extend([f"delegated:{cap}" for cap in agent_info["capabilities"]])
            
        return list(set(capabilities))  # Remove duplicates
    
    async def process(self, query: str, context: Optional[Dict] = None) -> AgentResponse:
        """
        Process a user query and return a response.
        
        This method:
        1. Analyzes the query to determine the best way to handle it
        2. Either handles directly or delegates to specialized agents
        3. Processes the response with TTS if enabled
        4. Maintains conversation history
        
        Args:
            query: User's query text
            context: Optional context information
            
        Returns:
            AgentResponse with the results
        """
        self.logger.info(f"Processing query: {query[:50]}...")
        self.set_state("processing")
        context = context or {}
        
        # Store in conversation history
        self.conversation_history.append({
            "role": "user",
            "content": query,
            "timestamp": context.get("timestamp")
        })
        
        try:
            # Determine if this query needs specialized handling
            agent_type, response = await self._determine_agent_for_query(query, context)
            
            # If we already have a response (e.g. from agent determination), return it
            if response:
                return self._finalize_response(response, query, context)
            
            # Handle based on the determined agent type
            if agent_type == "direct":
                # Handle directly - simple responses that don't need specialized agents
                response = await self._handle_direct_query(query, context)
            elif agent_type == "orchestrator" and self.orchestrator_id:
                # Use orchestrator for complex tasks requiring multiple agents
                response = await self._handle_via_orchestrator(query, context)
            else:
                # Use a specific specialized agent
                response = await self._handle_via_specialized_agent(agent_type, query, context)
            
            # Process the response (add to history, apply TTS)
            return self._finalize_response(response, query, context)
            
        except Exception as e:
            self.logger.error(f"Error processing query: {str(e)}")
            self.set_state("error")
            
            error_response = AgentResponse(
                content=f"Lo siento, no pude procesar esa solicitud debido a un error: {str(e)}",
                status="error",
                metadata={"error": str(e)}
            )
            
            return self._finalize_response(error_response, query, context)
    
    def _finalize_response(self, response: AgentResponse, query: str, context: Dict) -> AgentResponse:
        """
        Finalize the response by adding to history and processing TTS.
        
        Args:
            response: The response to finalize
            query: Original query
            context: Request context
            
        Returns:
            Processed response
        """
        # Add to conversation history
        self.conversation_history.append({
            "role": "assistant",
            "content": response.content,
            "status": response.status,
            "timestamp": context.get("timestamp")
        })
        
        # Store in memory if available
        if self.has_memory():
            convo_entry = {
                "query": query,
                "response": response.content,
                "status": response.status
            }
            self.remember(
                content=convo_entry,
                memory_type="conversation",
                metadata={"query": query}
            )
        
        # Process TTS if enabled
        if self.has_tts():
            # Force TTS voice based on assistant name
            tts_context = context.copy() if context else {}
            tts_context["tts_params"] = tts_context.get("tts_params", {})
            tts_context["tts_params"]["voice_name"] = self.default_voice
            tts_context["use_tts"] = True
            
            # Set play_audio to True by default for V.I.O.
            if "play_audio" not in tts_context:
                tts_context["play_audio"] = True
                
            response = self._process_tts_response(response, tts_context)
        
        # Reset state
        self.set_state("idle")
        
        return response
    
    async def _determine_agent_for_query(self, query: str, context: Optional[Dict] = None) -> tuple:
        """
        Determine which agent should handle the given query.
        
        Args:
            query: User's query to analyze
            context: Optional context information
            
        Returns:
            tuple: (agent_type, optional_response)
        """
        # Si el contexto especifica expl√≠citamente un agente, usar ese
        if context and "agent_type" in context:
            self.logger.info(f"Usando agente expl√≠cito desde contexto: {context['agent_type']}")
            return context["agent_type"], None
        
        # Normalizar consulta para patrones m√°s robustos (elimina acentos, signos, y corrige palabras pegadas)
        query_lower = query.lower().strip()
        query_normalized = self._normalize_query(query)
        
        self.logger.debug(f"Consulta original: '{query}', normalizada: '{query_normalized}'")
        
        # 1. DETECCI√ìN DE PATRONES DE ALTO NIVEL - Respuestas directas
        # ===========================================================
        
        # PATRONES CONVERSACIONALES: Saludos, c√≥mo est√°s, etc.
        conversation_patterns = {
            "greetings": ["hola", "buenos dias", "buenas tardes", "buenas noches", "hey", "saludos", "que tal"],
            "farewells": ["adios", "hasta luego", "nos vemos", "chao", "bye", "hasta pronto"],
            "how_are_you": ["como estas", "como te va", "como te encuentras", "que tal estas", "como te sientes"],
            "thank_you": ["gracias", "te lo agradezco", "muy amable", "gracias por tu ayuda"]
        }
        
        # Verificar patrones conversacionales
        for pattern_type, patterns in conversation_patterns.items():
            for pattern in patterns:
                if pattern in query_normalized or query_normalized.startswith(pattern):
                    self.logger.info(f"Detectado patr√≥n conversacional: {pattern_type} - '{pattern}'")
                    
                    # Estos patrones b√°sicos deben manejarse directamente
                    return "direct", None
        
        # 1.1 CONSULTAS EMOCIONALES Y DE EXPERIENCIA DE USUARIO
        # Estas deben manejarse directamente por V.I.O.
        emotion_experience_patterns = [
            "me siento", "siento que", "se siente", "me parece", 
            "es frustrante", "estoy frustrado", "frustracion", 
            "no funciona", "no sirve", "no entiendo", 
            "no se que hacer", "ayudame", "necesito ayuda",
            "experiencia", "opinion", "te parece", "crees que",
            "estas sintiendo", "que sientes", "como se siente"
        ]
        
        if any(pattern in query_normalized for pattern in emotion_experience_patterns):
            self.logger.info(f"Detectada consulta emocional o de experiencia: '{query_normalized}'")
            return "direct", None
        
        # Despedidas - responder directamente
        farewell_phrases = ["me voy", "hasta luego", "nos vemos despues", "hablamos luego"]
        if any(phrase in query_normalized for phrase in farewell_phrases):
            self.logger.info("Detectada frase de despedida, respondiendo directamente")
            return "direct", AgentResponse(content="¬°Hasta pronto! Estar√© aqu√≠ cuando me necesites.")
        
        # 2. CLASIFICACI√ìN DE CONSULTAS POR TIPO
        # ======================================
        
        # A. DETECTAR SOLICITUDES DE GENERACI√ìN DE C√ìDIGO
        # Patr√≥n 1: Verbos espec√≠ficos de creaci√≥n + programaci√≥n
        code_generation_verbs = [
            "crea", "crear", "genera", "generar", "escribe", "escribir", "implementa", "implementar", 
            "programa", "programar", "desarrolla", "desarrollar", "codifica", "codificar"
        ]
        
        code_objects = [
            "programa", "codigo", "funcion", "script", "clase", "metodo", "aplicacion", 
            "app", "algoritmo", "modulo", "libreria", "codigo fuente"
        ]
        
        languages = ["python", "javascript", "java", "c++", "typescript", "html", "css", "php", "ruby", "go"]
        
        # Patr√≥n muy espec√≠fico: verbo + objeto de c√≥digo + lenguaje
        is_code_generation = False
        
        # Verificaci√≥n de patrones de generaci√≥n de c√≥digo - usando consulta normalizada
        for verb in code_generation_verbs:
            if verb in query_normalized:
                # Buscar objetos de c√≥digo cerca del verbo
                for obj in code_objects:
                    if obj in query_normalized:
                        is_code_generation = True
                        self.logger.info(f"Detectada solicitud de generaci√≥n de c√≥digo: verbo='{verb}' + objeto='{obj}'")
                        break
                
                # Buscar lenguajes de programaci√≥n
                for lang in languages:
                    if lang in query_normalized:
                        is_code_generation = True
                        self.logger.info(f"Detectada solicitud de generaci√≥n de c√≥digo: verbo='{verb}' + lenguaje='{lang}'")
                        break
        
        # Expresiones espec√≠ficas que indican generaci√≥n de c√≥digo
        code_generation_patterns = [
            "codigo para", "funcion que", "programa que", "implementacion de",
            "escribir un algoritmo", "desarrollar una clase", "crear un script"
        ]
        
        if any(pattern in query_normalized for pattern in code_generation_patterns):
            is_code_generation = True
            self.logger.info(f"Patr√≥n espec√≠fico de generaci√≥n de c√≥digo detectado")
        
        if is_code_generation:
            self.logger.info("Solicitud de generaci√≥n de c√≥digo confirmada, asignando a CodeAgent")
            return "code", None
        
        # B. DETECTAR SOLICITUDES DE EXPLICACI√ìN DE CONCEPTOS
        # (Estas van al memory_agent para b√∫squeda de conocimiento)
        explanation_patterns = [
            "que es", "explica", "explicame", "explicacion de", "definicion de", 
            "significado de", "dime que", "cuentame sobre",
            "hablame de", "que significa"
        ]
        
        # Verificar patrones de solicitud de explicaci√≥n usando consulta normalizada
        is_explanation_request = False
        for pattern in explanation_patterns:
            if pattern in query_normalized and not is_code_generation:
                is_explanation_request = True
                self.logger.info(f"Detectada solicitud de explicaci√≥n: '{pattern}'")
                break
        
        # Si tenemos una solicitud de explicaci√≥n sobre un lenguaje de programaci√≥n
        # pero no es de generaci√≥n de c√≥digo, asignar al memory_agent
        if is_explanation_request and any(lang in query_normalized for lang in languages):
            self.logger.info("Solicitud de explicaci√≥n sobre lenguaje de programaci√≥n, asignando a MemoryAgent")
            return "memory", None
        
        # C. DETECTAR CONSULTAS SOBRE HARDWARE/SISTEMA
        # Esto debe tener alta prioridad para evitar confusiones con "memoria"
        hardware_terms = ["ram", "cpu", "procesador", "disco", "almacenamiento", "hardware", 
                         "sistema operativo", "windows", "linux", "mac", "red", "driver"]
        
        system_verbs = ["ejecuta", "abre", "cierra", "configura", "instala", "desinstala", 
                       "actualiza", "reinicia", "apaga", "muestra"]
        
        # Patrones espec√≠ficos de sistema
        system_patterns = [
            "sistema operativo", "archivos de", "carpeta", "directorio", "espacio en disco",
            "uso de memoria", "memoria ram", "proceso", "comando", "terminal", "consola"
        ]
        
        # Verificar patrones de sistema usando consulta normalizada
        if (any(term in query_normalized for term in hardware_terms) or
            any(pattern in query_normalized for pattern in system_patterns) or
            any(verb in query_normalized for verb in system_verbs)):
            self.logger.info("Detectada consulta sobre hardware/sistema, asignando a SystemAgent")
            return "system", None
        
        # D. DETECTAR TAREAS COMPLEJAS QUE REQUIEREN ORQUESTACI√ìN
        orchestration_indicators = [
            "paso a paso", "workflow", "flujo de trabajo", "secuencia de pasos",
            "primero", "luego", "despues", "finalmente", "coordina", "coordinar",
            "y posteriormente", "a continuacion", "trabajo en equipo"
        ]
        
        # Verificar indicadores de orquestaci√≥n usando consulta normalizada
        if any(indicator in query_normalized for indicator in orchestration_indicators) and self.orchestrator_id:
            self.logger.info("Detectada tarea compleja que requiere orquestaci√≥n")
            return "orchestrator", None
        
        # 3. PUNTUACI√ìN DE AGENTES BASADA EN T√âRMINOS DETECTADOS
        # =====================================================
        
        # Mejora: Patrones m√°s espec√≠ficos y prioritarios para cada tipo de agente
        agent_patterns = {
            "code": [
                # Patrones expl√≠citos de programaci√≥n
                "c√≥digo", "funci√≥n", "programa", "script", "clase", "m√©todo", 
                "algoritmo", "implementaci√≥n", "biblioteca", "librer√≠a", "api",
                "desarrollo", "programaci√≥n", "compilador", "int√©rprete",
                # Lenguajes de programaci√≥n
                "python", "javascript", "java", "c++", "c#", "typescript",
                "bash", "php", "ruby", "golang", "rust", "swift",
                # T√©rminos de desarrollo
                "bug", "error", "depuraci√≥n", "debugging", "c√≥digo fuente", "variable", 
                "constante", "bucle", "loop", "condicional", "if", "else", "for", "while"
            ],
            "system": [
                # Operaciones de sistema
                "ejecuta", "abre", "archivo", "directorio", "sistema operativo", 
                "comando", "lista archivos", "muestra el contenido", "crea carpeta",
                "elimina archivo", "renombra", "copia", "mueve", "ruta",
                "permisos", "terminal", "proceso", "ram", "cpu", "disco", "espacio",
                "windows", "linux", "mac", "macos", "ubuntu", "debian", "fedora"
            ],
            "memory": [
                # T√©rminos de conocimiento/informaci√≥n
                "informaci√≥n", "conocimiento", "dato", "recuerda", "olvida", 
                "aprende", "memoriza", "b√∫squeda", "busca", "encuentra",
                "qu√© es", "que es", "explica", "definici√≥n", "significado",
                "h√°blame", "cu√©ntame", "dime", "sabes", "conoces",
                # √Åreas de conocimiento
                "historia", "ciencia", "matem√°ticas", "geograf√≠a", "literatura",
                "filosof√≠a", "medicina", "biolog√≠a", "qu√≠mica", "f√≠sica",
                "econom√≠a", "pol√≠tica", "sociedad", "tecnolog√≠a", "arte"
            ]
        }
        
        # Verificar coincidencias para cada agente, con ponderaciones mejoradas
        match_scores = {"code": 0, "system": 0, "memory": 0}
        
        # Registro de coincidencias para debugging
        matches_log = {"code": [], "system": [], "memory": []}
        
        # Analizar cada palabra de la consulta
        query_words = query_normalized.split()
        
        for agent_type, patterns in agent_patterns.items():
            for pattern in patterns:
                # Buscar coincidencias exactas de t√©rminos completos
                if f" {pattern} " in f" {query_normalized} " or query_normalized.startswith(f"{pattern} ") or query_normalized.endswith(f" {pattern}"):
                    match_scores[agent_type] += 2
                    matches_log[agent_type].append(f"{pattern}(+2)")
                # Coincidencia parcial
                elif pattern in query_normalized:
                    match_scores[agent_type] += 1
                    matches_log[agent_type].append(f"{pattern}(+1)")
        
        # Verificar t√©rminos espec√≠ficos que podr√≠an causar confusi√≥n
        if "memoria" in query_normalized and not any(h_term in query_normalized for h_term in hardware_terms):
            if any(term in query_normalized for term in ["guardar", "recordar", "olvidar", "informaci√≥n"]):
                # Probablemente se refiere a la funcionalidad de memoria de la IA
                match_scores["memory"] += 3
                matches_log["memory"].append("memoria_sem√°ntica(+3)")
            else:
                # Podr√≠a referirse a RAM, verificar contexto
                context_terms = ["sistema", "computadora", "ordenador", "pc", "libre", "disponible"]
                if any(term in query_normalized for term in context_terms):
                    match_scores["system"] += 3
                    match_scores["memory"] -= 1  # Penalizar memory
                    matches_log["system"].append("memoria_hardware(+3)")
                    matches_log["memory"].append("penalizaci√≥n(-1)")
        
        # Log detallado para debugging
        for agent_type, matches in matches_log.items():
            if matches:
                self.logger.info(f"Coincidencias para {agent_type}: {', '.join(matches)}")
        
        self.logger.info(f"Puntuaciones finales: code={match_scores['code']}, system={match_scores['system']}, memory={match_scores['memory']}")
        
        # Determinar el agente ganador
        max_score = max(match_scores.values())
        if max_score > 0:
            # Encontrar todos los agentes con la puntuaci√≥n m√°xima
            best_agents = [agent for agent, score in match_scores.items() if score == max_score]
            
            if len(best_agents) == 1:
                # Claro ganador
                winner = best_agents[0]
                self.logger.info(f"Claro ganador: {winner} con puntuaci√≥n {max_score}")
            else:
                # Empate - aplicar reglas de desempate
                # Prioridad: code > system > memory
                priority_order = ["code", "system", "memory"]
                for agent_type in priority_order:
                    if agent_type in best_agents:
                        winner = agent_type
                        self.logger.info(f"Empate resuelto. Ganador por prioridad: {winner}")
                        break
                else:
                    # Si por alguna raz√≥n no se encuentra, usar el primero
                    winner = best_agents[0]
            
            # Verificaciones adicionales para casos especiales
            if winner == "memory" and "crear" in query_normalized and any(obj in query_normalized for obj in code_objects):
                self.logger.info("Reclasificando de memory a code debido a contexto de creaci√≥n")
                return "code", None
            
            return winner, None
        
        # Default a manejo directo
        self.logger.info("Sin coincidencias claras, usando manejo directo")
        return "direct", None
    
    def setup_memory(self, config: Dict):
        """
        Set up memory system for the agent.
        
        Args:
            config: Memory configuration
        """
        try:
            from memory.core import MemoryManager
            
            # Ensure we have a valid directory for memory storage
            data_dir = config.get("data_dir")
            if not data_dir:
                # Use a default directory if none specified
                data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "../../data/memory")
                self.logger.warning(f"No memory data_dir specified, using default: {data_dir}")
            
            # Ensure directory exists
            os.makedirs(data_dir, exist_ok=True)
            self.logger.info(f"Using memory data directory: {data_dir}")
                
            # Crear la configuraci√≥n correcta para el MemoryManager
            memory_config = {
                "short_term_memory": {
                    "retention_minutes": config.get("retention_minutes", 60),
                    "capacity": config.get("capacity", 100)
                },
                "long_term_memory": {
                    "min_importance": config.get("importance_threshold", 0.3)
                },
                "semantic_memory": {
                    "min_confidence": config.get("min_confidence", 0.0)
                },
                "use_long_term_memory": config.get("use_long_term_memory", True),
                "use_semantic_memory": config.get("use_semantic_memory", True),
                "use_episodic_memory": config.get("use_episodic_memory", False)
            }
            
            # Create MemoryManager with correct parameters
            self.memory_manager = MemoryManager(
                config=memory_config,
                data_dir=data_dir
            )
            
            # Configure memory options
            memory_threshold = config.get("threshold", 0.75)
            relevance_threshold = config.get("relevance_threshold", 0.65)
            importance_threshold = config.get("importance_threshold", 0.3)
            
            self.memory_options = {
                "threshold": memory_threshold,
                "relevance_threshold": relevance_threshold,
                "importance_threshold": importance_threshold
            }
            
            self.logger.info(f"Memory system initialized successfully with threshold={memory_threshold}")
            
        except Exception as e:
            self.logger.error(f"Error setting up memory manager: {str(e)}")
            self.logger.exception("Detailed memory initialization error:")
            self.memory_manager = None

    def _normalize_query(self, query: str) -> str:
        """
        Normaliza la consulta para hacer la detecci√≥n de patrones m√°s robusta.
        Corrige errores comunes de espacio y tipogr√°ficos.
        
        Args:
            query: Consulta original
            
        Returns:
            Consulta normalizada
        """
        # Convertir a min√∫sculas y eliminar espacios en blanco adicionales
        normalized = query.lower().strip()
        
        # Reemplazar caracteres especiales y acentos
        replacements = {
            '√°': 'a', '√©': 'e', '√≠': 'i', '√≥': 'o', '√∫': 'u',
            '√º': 'u', '√±': 'n', '?': ' ', '¬ø': ' ', '!': ' ', 
            '¬°': ' ', '.': ' ', ',': ' ', ';': ' ', ':': ' '
        }
        
        for char, replacement in replacements.items():
            normalized = normalized.replace(char, replacement)
        
        # Detectar y separar palabras pegadas comunes
        common_compounds = {
            'comote': 'como te',
            'quienes': 'quien es',
            'qui√©nes': 'qui√©n es',
            'quees': 'que es',
            'erestu': 'eres tu',
            'comofunciona': 'como funciona',
            'comose': 'como se'
        }
        
        for compound, separated in common_compounds.items():
            normalized = normalized.replace(compound, separated)
        
        # Eliminar duplicaci√≥n de espacios y palabras irrelevantes
        normalized = ' '.join(normalized.split())
        
        return normalized

    async def _handle_direct_query(self, query: str, context: Dict) -> AgentResponse:
        """
        Handle a query directly without using specialized agents.
        
        Args:
            query: User's query
            context: Request context
            
        Returns:
            AgentResponse with the result
        """
        # Obtener versiones normalizadas y originales para mayor robustez
        query_lower = query.lower().strip()
        query_normalized = self._normalize_query(query)
        
        # 1. PATRONES DE CONVERSACI√ìN B√ÅSICA
        # ==================================
        
        # Patrones de saludo mejorados
        greetings = ["hola", "buenos dias", "buenas tardes", "buenas noches", "hey", "saludos", 
                    "que tal", "como estas", "como vas", "que hay"]
        
        # Verificar si es un saludo simple - usando consulta normalizada
        is_greeting = False
        for greeting in greetings:
            if greeting in query_normalized or query_normalized.startswith(greeting):
                is_greeting = True
                break
        
        if is_greeting and len(query_normalized.split()) <= 5:
            # Respuestas de saludo variadas
            greeting_responses = [
                "Hola, ¬øen qu√© puedo ayudarte hoy?",
                "Hola. Dime, ¬øen qu√© te puedo ayudar?",
                "Hola, estoy listo para asistirte. ¬øQu√© necesitas?",
                "Saludos. ¬øEn qu√© puedo serte √∫til?",
                "Hola. ¬øQu√© tienes en mente hoy?"
            ]
            import random
            response_text = random.choice(greeting_responses)
            return AgentResponse(content=response_text)
        
        # 1.1 RESPUESTAS A CONSULTAS DE DISCULPA Y CONFUSI√ìN
        # ==================================================
        
        # Patrones de disculpa, confusi√≥n y no saber qu√© hacer
        confusion_patterns = [
            "lo siento", "perdon", "disculpa", "no se", "no s√©", "no entiendo", 
            "estoy confundido", "estoy confundida", "no se que pensar", "no se que hacer",
            "no hay", "no ahy", "no existe", "que opciones hay", "opciones", "alternativas",
            "que otra cosa", "otra opcion", "otra alternativa", "algo mas", "algo mejor"
        ]
        
        is_confusion = False
        for pattern in confusion_patterns:
            if pattern in query_normalized:
                is_confusion = True
                break
        
        if is_confusion:
            # Presentar opciones claras y significativas
            clear_options = """
üìã OPCIONES DISPONIBLES:

1Ô∏è‚É£ AYUDA CON C√ìDIGOS - Puedo generar, explicar o corregir c√≥digo en varios lenguajes
   Ejemplo: "Crea una funci√≥n en Python que ordene una lista"

2Ô∏è‚É£ INFORMACI√ìN DEL SISTEMA - Puedo consultar datos de tu equipo
   Ejemplo: "Cu√°nta memoria RAM tengo disponible"

3Ô∏è‚É£ B√öSQUEDA DE CONOCIMIENTO - Puedo buscar informaci√≥n en mi memoria
   Ejemplo: "Expl√≠came qu√© es la inteligencia artificial"

4Ô∏è‚É£ TAREAS COMPLEJAS - Puedo coordinar m√∫ltiples agentes para tareas elaboradas
   Ejemplo: "Crea un programa que analice archivos y muestre estad√≠sticas"

5Ô∏è‚É£ CONVERSACI√ìN GENERAL - Puedo charlar contigo sobre diversos temas
   Ejemplo: "Hablemos sobre tecnolog√≠a"

Por favor, selecciona una opci√≥n escribiendo tu consulta espec√≠fica.
"""
            return AgentResponse(
                content=clear_options.strip(),
                metadata={"response_type": "options_menu", "user_confused": True}
            )
        
        # Patrones de despedida
        farewells = ["adios", "hasta luego", "nos vemos", "chao", "bye", "hasta pronto"]
        
        is_farewell = False
        for farewell in farewells:
            if farewell in query_normalized or query_normalized.startswith(farewell):
                is_farewell = True
                break
        
        if is_farewell:
            # Respuestas de despedida variadas
            farewell_responses = [
                "¬°Hasta pronto! Estoy aqu√≠ cuando me necesites.",
                "Adi√≥s. Regresa cuando necesites mi ayuda.",
                "Nos vemos. Estar√© aqu√≠ para la pr√≥xima consulta.",
                "Hasta luego. Ha sido un placer asistirte."
            ]
            import random
            return AgentResponse(content=random.choice(farewell_responses))
        
        # 1.2 RESPUESTAS A CONSULTAS EMOCIONALES Y EXPERIENCIA DE USUARIO
        # ===============================================================
        
        # Patrones de experiencia negativa o dificultad
        frustration_patterns = [
            "no funciona", "no sirve", "no entiendo", "no se que hacer",
            "es frustrante", "frustracion", "estoy frustrado", "siento frustracion",
            "se siente mal", "experiencia", "decepcionado", "decepcion", 
            "mal servicio", "mala respuesta", "no me gusta", "no me sirve"
        ]
        
        is_frustration = False
        for pattern in frustration_patterns:
            if pattern in query_normalized:
                is_frustration = True
                break
        
        if is_frustration:
            empathetic_responses = [
                "Entiendo tu frustraci√≥n. Estoy trabajando para mejorar. ¬øPodr√≠as decirme espec√≠ficamente qu√© esperabas que hiciera diferente?",
                "Lamento que la experiencia no est√© siendo satisfactoria. Perm√≠teme intentar ayudarte de otra manera. ¬øQu√© est√°s intentando lograr exactamente?",
                "Comprendo tu frustraci√≥n. Todav√≠a estoy aprendiendo. ¬øPodr√≠amos intentar un enfoque diferente para resolver tu problema?",
                "Siento que esto no est√© funcionando como esperabas. Intentemos otra aproximaci√≥n. ¬øPuedes describir nuevamente lo que necesitas, quiz√°s con otras palabras?"
            ]
            import random
            return AgentResponse(
                content=random.choice(empathetic_responses),
                metadata={"response_type": "empathetic", "frustration_detected": True}
            )
        
        # Patrones de consulta emocional sobre el sistema
        emotion_query_patterns = [
            "como te sientes", "que sientes", "estas sintiendo", "tienes emociones",
            "tienes sentimientos", "te gusta", "te emociona", "te entristece",
            "eres feliz", "eres triste", "te preocupa", "te molesta"
        ]
        
        is_emotion_query = False
        for pattern in emotion_query_patterns:
            if pattern in query_normalized:
                is_emotion_query = True
                break
        
        if is_emotion_query:
            ai_emotion_responses = [
                "Como asistente, no tengo emociones reales, pero estoy programado para entender emociones humanas y responder adecuadamente. Mi enfoque est√° completamente en ayudarte lo mejor posible.",
                "No experimento emociones como los humanos, pero puedo reconocerlas y responder a ellas. Mi objetivo principal es brindarte la mejor asistencia que pueda.",
                "No siento emociones en el sentido humano, pero s√≠ estoy dise√±ado para entender contextos emocionales y adaptarme a ellos. Estoy aqu√≠ para apoyarte con cualquier tarea que necesites."
            ]
            import random
            return AgentResponse(
                content=random.choice(ai_emotion_responses),
                metadata={"response_type": "emotion_explanation"}
            )
        
        # 2. CONSULTAS SOBRE EL SISTEMA Y CAPACIDADES
        # =========================================== 
        
        # Patrones de consulta sobre capacidades - Significativamente ampliados
        capability_patterns = [
            "que puedes hacer", "cuales son tus habilidades", "dime que haces", 
            "tus funcionalidades", "como me puedes ayudar", "que sabes hacer",
            "quiero saber que puedes hacer", "explicame que puedes hacer",
            "cuales son tus capacidades", "de que eres capaz", "ayuda",
            "que eres capaz de hacer", "para que sirves", "como funcionas",
            "que funciones tienes", "dime tus capacidades", "cual es tu proposito",
            "para que te usan", "que se puede hacer contigo"
        ]
        
        # Verificar consultas de capacidades
        is_capability_query = False
        for pattern in capability_patterns:
            if pattern in query_normalized:
                is_capability_query = True
                break
        
        if is_capability_query or "que haces" in query_normalized:
            capabilities = self._get_system_capabilities_description()
            capability_responses = [
                f"Puedo ayudarte con varias tareas, incluyendo: {capabilities}. ¬øEn qu√© √°rea necesitas asistencia ahora?",
                f"Mis capacidades incluyen: {capabilities}. ¬øCon qu√© te gustar√≠a comenzar?",
                f"Estoy dise√±ado para asistirte con: {capabilities}. ¬øEn qu√© puedo ayudarte espec√≠ficamente?"
            ]
            import random
            response_text = random.choice(capability_responses)
            return AgentResponse(content=response_text)
        
        # Preguntas de identidad - con mayor tolerancia a variaciones
        identity_patterns = [
            "quien eres", "como te llamas", "cual es tu nombre", "presentate",
            "quien eres tu", "quien es vio", "que es vio", "que significa vio",
            "quien esta ahi", "con quien hablo", "a quien le hablo", "identificate", 
            "tu identidad", "eres un asistente", "eres una ia", "eres un agente"
        ]
        
        is_identity_query = False
        for pattern in identity_patterns:
            if pattern in query_normalized:
                is_identity_query = True
                break
        
        if is_identity_query:
            identity_responses = [
                f"Soy {self.name}, tu asistente virtual. Coordino diferentes agentes especializados para ayudarte con tus tareas y consultas.",
                f"Me llamo {self.name} (Virtual Intelligence Operator). Estoy dise√±ado para asistirte gestionando un sistema de agentes especializados.",
                f"{self.name} a tu servicio. Mi funci√≥n es coordinar agentes especializados y mantener memoria persistente para brindarte la mejor asistencia posible."
            ]
            import random
            response_text = random.choice(identity_responses)
            return AgentResponse(content=response_text)
        
        # 3. CONSULTAS DE MEMORIA
        # ======================
        
        # Consultas de memoria b√°sicas
        memory_queries = [
            "recuerdas", "me dijiste", "mencionaste", "dijimos antes",
            "hablamos de", "te cont√©", "te dije", "ya te hab√≠a dicho",
            "comentaste", "hab√≠amos hablado", "dije antes"
        ]
        
        if any(term in query_lower for term in memory_queries):
            if self.has_memory():
                memories = self.recall(query=query, limit=3)
                if memories:
                    memory_content = memories[0].content
                    if isinstance(memory_content, dict) and "response" in memory_content:
                        memory_text = memory_content["response"]
                    else:
                        memory_text = str(memory_content)
                    
                    memory_responses = [
                        f"S√≠, recuerdo que: {memory_text}",
                        f"Seg√∫n lo que hablamos antes: {memory_text}",
                        f"Tengo registro de eso: {memory_text}"
                    ]
                    import random
                    return AgentResponse(
                        content=random.choice(memory_responses),
                        metadata={"memory_used": True, "memories_found": len(memories)}
                    )
            
            # Si llegamos aqu√≠, no se encontraron memorias relevantes
            no_memory_responses = [
                "No recuerdo nada espec√≠fico sobre eso. ¬øPodr√≠as darme m√°s detalles?",
                "No tengo registro de esa informaci√≥n en mi memoria. ¬øPuedes ser m√°s espec√≠fico?",
                "No encuentro informaci√≥n relacionada con esa consulta en mi memoria."
            ]
            import random
            return AgentResponse(
                content=random.choice(no_memory_responses),
                metadata={"memory_used": False}
            )
        
        # 4. CONSULTAS SOBRE USUARIO
        # ========================
        
        # Consultas espec√≠ficas sobre el perfil del usuario
        user_queries = [
            "qui√©n soy", "c√≥mo me llamo", "qu√© sabes de m√≠", "mi perfil", "mis intereses",
            "mi informaci√≥n", "qu√© recuerdas de m√≠", "mis datos", "informaci√≥n sobre m√≠"
        ]
        
        if any(term in query_lower for term in user_queries) and self.has_memory():
            # Buscar en memoria con metadatos espec√≠ficos
            user_memories = self.memory_manager.search_memories(
                query=query,
                memory_type="user_profile",
                limit=2
            )
            
            if user_memories:
                memory = user_memories[0]
                # Extraer un fragmento relevante
                content = str(memory.content)
                if len(content) > 200:
                    content = content[:200] + "..."
                    
                user_responses = [
                    f"Seg√∫n tu perfil: {content}",
                    f"Tengo esta informaci√≥n sobre ti: {content}",
                    f"En mi memoria sobre ti: {content}"
                ]
                import random
                return AgentResponse(
                    content=random.choice(user_responses),
                    metadata={"memory_used": True, "memory_type": "user_profile"}
                )
        
        # 5. CONSULTAS ESPEC√çFICAS SOBRE ESTE SISTEMA
        # =========================================
        
        system_queries = [
            "c√≥mo funciona este sistema", "qu√© agentes hay", "qu√© es este sistema",
            "arquitectura del sistema", "componentes del sistema", "explicame este sistema",
            "c√≥mo est√°n organizados los agentes", "qui√©n te desarroll√≥"
        ]
        
        if any(term in query_lower for term in system_queries):
            system_description = f"""
Este sistema, liderado por V.I.O. (Virtual Intelligence Operator), utiliza una arquitectura multiagente con el Model Context Protocol (MCP).

Los principales componentes incluyen:
- Agente principal (V.I.O.): Coordinador central que delega tareas
- Agentes especializados: Code, System, Memory y otros seg√∫n la configuraci√≥n
- Sistema de memoria: Almacena informaci√≥n persistente con b√∫squeda sem√°ntica
- MCP: Protocolo que facilita la comunicaci√≥n entre componentes

Actualmente hay {len(self.specialized_agents)} agentes especializados disponibles para procesar diferentes tipos de consultas.
"""
            return AgentResponse(content=system_description.strip())
        
        # 6. RESPUESTA GEN√âRICA PARA CONSULTAS NO RECONOCIDAS
        # =================================================
        
        # Intentar extraer palabras clave para dar una respuesta m√°s personalizada
        important_terms = []
        for word in query_lower.split():
            if len(word) > 4 and word not in ["como", "c√≥mo", "para", "poder", "puedes", "d√≥nde", "cu√°ndo", "cu√°les"]:
                important_terms.append(word)
        
        if important_terms:
            generic_responses = [
                f"Entiendo que preguntas sobre {', '.join(important_terms[:2])}. ¬øPodr√≠as reformular tu consulta?",
                f"No estoy seguro de c√≥mo responderte sobre {', '.join(important_terms[:2])}. ¬øPuedes ser m√°s espec√≠fico?",
                f"Para ayudarte mejor con {', '.join(important_terms[:2])}, ¬øpodr√≠as dar m√°s contexto?"
            ]
        else:
            generic_responses = [
                "No estoy seguro de entender tu consulta. ¬øPodr√≠as expresarla de otra forma?",
                "Necesito m√°s detalles para poder ayudarte adecuadamente.",
                "No tengo suficiente contexto para responder. ¬øPodr√≠as elaborar m√°s tu pregunta?"
            ]
        
        import random
        return AgentResponse(
            content=random.choice(generic_responses),
            metadata={"action": "suggest_reformulation"}
        )
    
    async def _handle_via_orchestrator(self, query: str, context: Dict) -> AgentResponse:
        """
        Handle a query via the orchestrator agent.
        
        Args:
            query: User's query
            context: Request context
            
        Returns:
            AgentResponse with the result
        """
        self.logger.info(f"Delegating query to orchestrator: {query[:50]}...")
        
        # Ensure we're registered with communicator
        await self.register_with_communicator()
        
        # Prepare context for orchestrator
        orchestrator_context = {
            "from_main_assistant": True,
            "original_query": query,
            **(context or {})
        }
        
        # Send request to orchestrator
        response = await self.send_request_to_agent(
            self.orchestrator_id,
            query,
            orchestrator_context
        )
        
        if not response:
            return AgentResponse(
                content="Lo siento, el orquestador no est√° disponible en este momento. Puedo intentar manejar tu solicitud de otra manera.",
                status="error",
                metadata={"error": "orchestrator_unavailable"}
            )
            
        return response
    
    async def _handle_via_specialized_agent(self, agent_type: str, query: str, context: Dict) -> AgentResponse:
        """
        Handle a query by delegating to a specialized agent.
        
        Args:
            agent_type: Type of agent to use
            query: User's query
            context: Request context
            
        Returns:
            AgentResponse with the result
        """
        self.logger.info(f"Delegating query to {agent_type} agent: {query[:50]}...")
        
        # Find an appropriate agent ID based on type
        agent_id = self._find_agent_id_by_type(agent_type)
        
        if not agent_id:
            return AgentResponse(
                content=f"Lo siento, no tengo un agente de tipo {agent_type} disponible en este momento.",
                status="error",
                metadata={"error": "agent_unavailable"}
            )
            
        # Ensure we're registered with communicator
        await self.register_with_communicator()
        
        # Prepare context for specialized agent
        agent_context = {
            "from_main_assistant": True,
            "original_query": query,
            **(context or {})
        }
        
        # Add task-specific context
        if agent_type == "code":
            agent_context["task"] = "generate"  # Default task for code agent
            
            # Detect language from query
            for lang in ["python", "javascript", "java", "c++", "c#"]:
                if lang in query.lower():
                    agent_context["language"] = lang
                    break
        
        # Send request to specialized agent
        response = await self.send_request_to_agent(
            agent_id,
            query,
            agent_context
        )
        
        if not response:
            return AgentResponse(
                content=f"Lo siento, el agente especializado no est√° disponible en este momento.",
                status="error",
                metadata={"error": "agent_unavailable"}
            )
        
        # A√±adir informaci√≥n de delegaci√≥n a los metadatos para facilitar pruebas
        if isinstance(response, AgentResponse):
            # Agregar informaci√≥n de delegaci√≥n a los metadatos existentes
            response.metadata["delegated"] = True
            response.metadata["delegated_to"] = agent_id
            response.metadata["delegated_type"] = agent_type
            response.metadata["original_agent_id"] = self.agent_id
        else:
            # Si por alguna raz√≥n response no es un AgentResponse, lo convertimos
            response = AgentResponse(
                content=response.content if hasattr(response, "content") else str(response),
                status="success",
                metadata={
                    "delegated": True,
                    "delegated_to": agent_id,
                    "delegated_type": agent_type,
                    "original_agent_id": self.agent_id
                }
            )
            
        return response
    
    def _find_agent_id_by_type(self, agent_type: str) -> Optional[str]:
        """
        Find a suitable agent ID based on the agent type.
        
        Args:
            agent_type: Type of agent to find
            
        Returns:
            Agent ID if found, None otherwise
        """
        # Mapeo directo mejorado para tipos de agentes comunes
        type_to_id_map = {
            "code": "code",
            "system": "system",
            "echo": "echo",
            "memory": "memory",
            "orchestrator": "orchestrator"
        }
        
        # Mapeo de tipos alternativos a los tipos est√°ndar
        alternative_types = {
            # Programaci√≥n
            "programming": "code",
            "development": "code",
            "coding": "code",
            "developer": "code",
            "script": "code",
            "python": "code",
            "javascript": "code",
            # Sistema
            "os": "system",
            "filesystem": "system",
            "file": "system",
            "directory": "system",
            "command": "system",
            "hardware": "system",
            # Memoria
            "semantic": "memory",
            "knowledge": "memory",
            "recall": "memory",
            "information": "memory",
            "query": "memory"
        }
        
        # Normalizar el tipo de agente
        normalized_type = alternative_types.get(agent_type, agent_type)
        
        # Primero intentar mapeo directo con el tipo normalizado
        if normalized_type in type_to_id_map:
            agent_id = type_to_id_map[normalized_type]
            # Verificar si este agente est√° registrado
            if agent_id in self.specialized_agents:
                self.logger.info(f"Usando mapeo directo: {agent_type} -> {normalized_type} -> {agent_id}")
                return agent_id
            else:
                self.logger.warning(f"Agente mapeado {agent_id} no est√° registrado. Buscando alternativas.")
        
        # Capacidades espec√≠ficas que deben coincidir con tipos de agentes    
        capability_to_type = {
            "code": ["code", "programming", "development", "python", "javascript"],
            "system": ["system", "filesystem", "command", "file_operations", "system_operations"],
            "memory": ["memory", "remember", "recall", "vector_search", "semantic_search"]
        }
        
        # Buscar agentes que tengan capacidades relacionadas con el tipo
        candidates = {}
        for agent_id, info in self.specialized_agents.items():
            capabilities = info["capabilities"]
            score = 0
            
            # Verificar coincidencia directa
            if normalized_type in capabilities:
                score += 5
                
            # Verificar coincidencias en capacidades seg√∫n el tipo normalizado
            if normalized_type in capability_to_type:
                relevant_capabilities = capability_to_type[normalized_type]
                for capability in capabilities:
                    if capability in relevant_capabilities:
                        score += 3
                    elif any(rel_cap in capability for rel_cap in relevant_capabilities):
                        score += 1
            
            if score > 0:
                candidates[agent_id] = score
        
        # Elegir el agente con la puntuaci√≥n m√°s alta
        if candidates:
            best_agent = max(candidates, key=candidates.get)
            self.logger.info(f"Mejor agente para {agent_type}: {best_agent} con puntuaci√≥n {candidates[best_agent]}")
            return best_agent
                
        # Si no se encuentra mapeo, buscar cualquier agente disponible que pueda servir
        self.logger.warning(f"No se encontr√≥ agente espec√≠fico para tipo {agent_type}, buscando agente gen√©rico")
        
        # Si necesitamos un agente de memoria y no lo encontramos, intentar usar cualquier agente disponible
        if agent_type == "memory" and self.specialized_agents:
            fallback_id = next(iter(self.specialized_agents.keys()))
            self.logger.warning(f"Usando agente gen√©rico {fallback_id} como √∫ltimo recurso para consulta de memoria")
            return fallback_id
            
        self.logger.warning(f"No se encontr√≥ ning√∫n agente para el tipo {agent_type}")
        return None
    
    def _get_system_capabilities_description(self) -> str:
        """
        Get a human-readable description of system capabilities.
        
        Returns:
            String describing capabilities
        """
        has_code = any("code" in agent_info["capabilities"] for agent_info in self.specialized_agents.values())
        has_system = any("system" in agent_info["capabilities"] for agent_info in self.specialized_agents.values())
        has_orchestrator = self.orchestrator_id is not None
        
        capabilities = []
        
        if has_code:
            capabilities.append("generar y analizar c√≥digo")
            
        if has_system:
            capabilities.append("interactuar con el sistema de archivos")
            
        if has_orchestrator:
            capabilities.append("resolver tareas complejas coordinando agentes especializados")
            
        capabilities.append("responder a tus preguntas")
        capabilities.append("conversar contigo por voz")
        
        if len(capabilities) == 1:
            return capabilities[0]
        elif len(capabilities) == 2:
            return f"{capabilities[0]} y {capabilities[1]}"
        else:
            return ", ".join(capabilities[:-1]) + f" y {capabilities[-1]}" 